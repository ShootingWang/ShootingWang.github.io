<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon2.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="统计一只狗，梦想有只猫">
  <meta name="author" content="ShootingWang">
  <meta name="keywords" content="">
  <title>熵 - ShootingWang</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_fmb4a04yx8h.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_ijqayz9ro8k.css">




<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<link rel="stylesheet" href="/js/prism/prism.css">

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>ShootingWang</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">
              <i class="iconfont icon-home-fill"></i>
              首页</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">
              <i class="iconfont icon-archive-fill"></i>
              归档</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">
              <i class="iconfont icon-category-fill"></i>
              分类</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">
              <i class="iconfont icon-tags-fill"></i>
              标签</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">
              <i class="iconfont icon-user-fill"></i>
              关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/bg/MalhamStars.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <div class="mt-3 post-meta">
                  <i class="iconfont icon-date-fill" aria-hidden="true"></i>
                  <time datetime="2020-05-15 20:29">
                    星期五, 五月 15日 2020, 8:29 晚上
                  </time>
                </div>
              

              <div class="mt-1">
                
                  
                  <span class="post-meta mr-2">
                    <i class="iconfont icon-chart"></i>
                    2.6k 字
                  </span>
                

                
                  
                  <span class="post-meta mr-2">
                      <i class="iconfont icon-clock-fill"></i>
                    
                    
                    36
                     分钟
                  </span>
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  <span id="busuanzi_container_page_pv" class="post-meta" style="display: none">
                    <i class="iconfont icon-eye" aria-hidden="true"></i>
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>
                
              </div>
            
          </div>

          
        </div>

        <a href="https://github.com/ShootingWang" class="attachment-full size-full" aria-label="Fork me on GitHub">
          <svg width="80" height="80" viewBox="0 0 250 250" style="fill:#fff; color:#151513; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true">
            <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
            <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
            <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path>
          </svg>
        </a>
        <style>

        .github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}
        </style>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <h1><span id="信息量">信息量</span></h1><p>信息量是对信息的度量；有时也叫作<strong>自信息</strong>（self-information）。</p>
<ul>
<li><p>信息的大小与随机事件发生的概率有关</p>
<ul>
<li><p>概率越小的事件发生了，产生的信息量越大</p>
<blockquote>
<p>如：处于非地震带的地方发生了地震</p>
</blockquote>
</li>
<li><p>概率越大的事件发生了，产生的信息量越小</p>
<blockquote>
<p>如太阳从东边升起</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p>因此，事件的信息量随着其发生概率而递减，且不为负</p>
<p><strong>信息量</strong>的公式：</p>
<script type="math/tex; mode=display">I(x)=-\log{p(x)}</script><p>其中，$p(x)$为随机事件$x$发生的概率；负号保证了信息量一定不为负。</p>
<ul>
<li><strong>联合自信息量</strong><script type="math/tex; mode=display">I(x_i,y_j)=-\log{p(x_i,y_j)}</script></li>
<li><strong>条件自信息量</strong><script type="math/tex; mode=display">I(y_j|x_i)=-\log{p(y_j|x_i)}</script></li>
</ul>
<h1><span id="信息熵香农熵">信息熵/香农熵</span></h1><p>Entropy</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><strong>信息量</strong></th>
<th style="text-align:center"><strong>信息熵</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">度量一个具体事件发生了所带来的信息</td>
<td style="text-align:center">在事件发生之前对其结果可能产生的信息量求期望</td>
</tr>
<tr>
<td style="text-align:center">对事件不确定性的度量</td>
<td style="text-align:center">事件所有可能结果的自信息的期望值</td>
</tr>
</tbody>
</table>
</div>
<p><strong>信息熵</strong>的公式如下：</p>
<script type="math/tex; mode=display">H(X)=-\sum_{i=1}^np(x_i)\log{p(x_i)}</script><p>其中$p(x_i)$表示随机事件$x_i\ (i=1,\cdots,n)$的概率。</p>
<p>假设一组数据由$D=\{d_1,d_2,\cdots,d_n\}$构成，则这组数据的信息熵为</p>
<script type="math/tex; mode=display">H(D)=-\sum_{i=1}^n\frac{d_i}{S_D}\log{\frac{d_i}{S_D}}</script><p>其中，$S_D=\sum_{i=1}^nd_i$。</p>
<h3><span id="对数的底">对数的底</span></h3><p>信息熵公式中的对数的底的选择是任意的</p>
<ul>
<li>信息论中，一般选取<strong>2</strong>作为对数的底，则信息的单位为<u>比特（bits）</u></li>
<li>机器学习中，一般选取<strong>自然常数e</strong>作为对数的底，则单位为<u>奈特（nats）</u></li>
</ul>
<h3><span id="性质">性质</span></h3><p>信息熵的一个性质为：</p>
<script type="math/tex; mode=display">0\leq H(X)\leq\log{n}</script><p>这里$n$表示事件的个数。</p>
<blockquote>
<p>即：当随机分布为均匀分布时，熵最大</p>
</blockquote>
<p><font face="仿宋"><br>证明：使用拉格朗日乘子法<br>因为$p(x_1)+p(x_2)+\cdots+p(x_n)=1$，所以目标函数为</font></p>
<script type="math/tex; mode=display">f\left(p(x_1),\cdots,p(x_n)\right)=-\left[p(x_1)\log{p(x_1)}+p(x_2)\log{p(x_2)}+\cdots+p(x_n)\log{p(x_n)}\right]</script><p><font face="仿宋">约束条件为</font></p>
<script type="math/tex; mode=display">g\left(p(x_1),\cdots,p(x_n)\right)=p(x_1)+p(x_2)+\cdots+p(x_n)-1=0</script><p><font face="仿宋">定义拉格朗日函数：<br>\begin{equation}<br>\begin{aligned}<br>L(p(x_1),\cdots,p(x_n);\lambda)&amp;=-\left[p(x_1)\log{p(x_1)}+p(x_2)\log{p(x_2)}+\cdots+p(x_n)\log{p(x_n)}\right]\\<br>&amp;+\lambda\left[p(x_1)+p(x_2)+\cdots+p(x_n)-1\right]<br>\end{aligned}<br>\end{equation}<br>$L(p(x_1),\cdots,p(x_n);\lambda)$分别对$p(x_1),p(x_2),\cdots,p(x_n),\lambda$求偏导，并令偏导数为0，得到<br>\begin{equation}<br>\left\{<br>\begin{array}{l}<br>\lambda-\log p(x_1)-1=0\\<br>\lambda-\log p(x_2)-1=0\\<br>\cdots\\<br>\lambda-\log p(x_n)-1=0\\<br>p(x_1)+p(x_2)+\cdots+p(x_n)-1=0<br>\end{array}\right.<br>\end{equation}<br>解上述方程组，可得</font></p>
<script type="math/tex; mode=display">p(x_1)=p(x_2)=\cdots=p(x_n)=\frac{1}{n}</script><p>&lt;/font&gt;</p>
<p><font face="仿宋">所以目标函数的极大值为</font></p>
<script type="math/tex; mode=display">f\left(\frac{1}{n},\frac{1}{n},\cdots,\frac{1}{n}\right)=-\left[\frac{1}{n}\log\frac{1}{n}+\frac{1}{n}\log\frac{1}{n}+\cdots+\frac{1}{n}\log\frac{1}{n}\right]=-\log\frac{1}{n}=\log n</script><p>&lt;/font&gt;<br>即：当随机分布为均匀分布时，熵最大。</p>
<h1><span id="联合熵复合熵">联合熵/复合熵</span></h1><p>联合熵/复合熵：度量两个随机变量$X$和$Y$在一起时的不确定性</p>
<p>假设</p>
<ul>
<li>离散情况：随机变量$(X,Y)$的联合概率分布为<script type="math/tex; mode=display">P(X=x_i,Y=y_j)=p_{ij},\ i=1,\cdots,n;\ j=1,\cdots,m</script></li>
<li>连续情况：随机变量$(X,Y)$的联合密度函数为<script type="math/tex; mode=display">f(x,y)\quad (x\in \Omega_X;\ y\in \Omega_Y)</script></li>
</ul>
<p><strong>复合熵/联合熵</strong>为</p>
<script type="math/tex; mode=display">H(X,Y)=-\sum_{i=1}^n\sum_{j=1}^mp_{ij}\log{p_{ij}}</script><script type="math/tex; mode=display">H(X,Y)=-\int_{\Omega_X}\int_{\Omega_Y}f(x,y)\log{f(x,y)}\mathrm{dx}\mathrm{dy}</script><h3><span id="性质">性质</span></h3><ul>
<li>联合熵大于独立熵的和<br>\begin{equation}<br>\begin{aligned}<br>H(X,Y)&amp;\geq\max{\left[H(X),H(Y) \right]}\\<br>H(X_1,\cdots,X_N)&amp;\geq\max{\left[H(X_1),\cdots,H(X_N) \right]}<br>\end{aligned}<br>\end{equation}</li>
<li>联合熵小于各独立熵的和<br>\begin{equation}<br>\begin{aligned}<br>H(X,Y)&amp;\leq H(X)+H(Y)\\<br>H(X_1,\cdots,X_N)&amp;\leq H(X_1)+\cdots+H(X_N)<br>\end{aligned}<br>\end{equation}</li>
</ul>
<h1><span id="条件熵">条件熵</span></h1><p>条件熵：代表在某一个条件$X$下，随机变量$Y$的复杂度（不确定度）</p>
<blockquote>
<p>即：在给定条件X下，Y的条件概率分布的熵关于X的数学期望</p>
</blockquote>
<p><strong>条件熵</strong>$H(Y|X)$表示在已知随机变量$X$的条件下、随机变量$Y$ 的不确定性。<br>\begin{equation}<br>\begin{aligned}<br>  H(Y|X) &amp;= \sum_{i=1}^np(x_i)H(Y|X=x_i)\\<br>&amp;= -\sum_{i=1}^np(x_i)\sum_{j=1}^mp(y_j|x_i)\log{p(y_j|x_i)}\\<br>&amp;= -\sum_{i=1}^n\sum_{j=1}^mp(x_i,y_j)\log{p(y_j|x_i)}\\<br>H(Y|X)&amp;= \int_{x\in\Omega_X}f(x)H(Y|X=x)\mathrm{dx}\\<br>&amp;= -\int_{x\in\Omega_X}f(x)\int_{y\in\Omega_Y}f(y|x)\log{f(y|x)}\mathrm{dy}\\<br>&amp;= -\int_{x\in\Omega_X}\int_{y\in\Omega_Y}f(x)f(y|x)\log{f(y|x)}\mathrm{dx}\mathrm{dy}<br>\end{aligned}<br>\end{equation}</p>
<p>当信息熵和条件熵中的概率由样本数据估计而得时，所对应的信息熵与条件熵称为<strong>经验熵</strong>（empirical entropy）和<strong>经验条件熵</strong>（empirical conditional entropy）。</p>
<h3><span id="性质">性质</span></h3><script type="math/tex; mode=display">H(Y|X)=H(X,Y)-H(X)</script><p><font face="仿宋"><br>证明：（仅证明离散情况）<br>\begin{equation}<br>\begin{aligned}<br>H(Y|X)&amp;= -\sum_{i=1}^n\sum_{j=1}^mp(x_i,y_j)\log{p(y_j|x_i)}\\<br>&amp;= -\sum_{i=1}^n\sum_{j=1}^mp(x_i,y_j)\log{\frac{p(x_i,y_j)}{p(x_i)}}\\<br>&amp;= -\sum_{i=1}^n\sum_{j=1}^mp(x_i,y_j)\left(\log{p(x_i,y_j)}-\log{p(x_i)}\right)\\<br>&amp;= -\sum_{i=1}^n\sum_{j=1}^m\left(p(x_i,y_j)\log{p(x_i,y_j)}-p(x_i,y_j)\log{p(x_i)}\right)\\<br>&amp;= -\sum_{i=1}^n\sum_{j=1}^mp(x_i,y_j)\log{p(x_i,y_j)}-\left(-\sum_{i=1}^n\sum_{j=1}^mp(x_i,y_j)\log{p(x_i)}\right)\\<br>&amp;= H(X,Y)-H(X)<br>\end{aligned}<br>\end{equation}
</font></p>
<p><font face="仿宋"><br>同理可得</font></p>
<script type="math/tex; mode=display">H(X|Y)=H(X,Y)-H(Y)</script><p><font face="仿宋">合并上述两个公式可得</font></p>
<script type="math/tex; mode=display">H(Y|X)+H(X)=H(X,Y)=H(X|Y)+H(Y)</script><p>体现了熵的对称性。</p>
<h1><span id="相对熵kl散度">相对熵/KL散度</span></h1><p><strong>相对熵</strong>，又称互熵、鉴别信息、Kullback熵、<strong>Kullback-Leible散度</strong>（KL散度），是两个概率分布间差异的非对称性度量；常常用来度量两个随机变量的“距离”。在信息论中，相对熵等价于两个概率分布的信息熵的差值。如果其中一个概率分布为真实分布，另一个为理论分布/拟合分布，则相对熵等于交叉熵与真实分布的信息熵之差，表示使用理论分布拟合真实分布时的信息损耗。</p>
<p>设$p(x)$和$q(x)$是两个概率分布，则$p$对$q$的相对熵为</p>
<script type="math/tex; mode=display">D_{KL}(p||q)=E_{p(x)}\left(\log{\frac{p(x)}{q(x)}}\right)=\sum_{i=1}^np(x_i)\log{\frac{p(x_i)}{q(x_i)}}</script><p>相对熵不具有对称性：</p>
<script type="math/tex; mode=display">D(p||q)\neq D(q||p)</script><h3><span id="性质">性质</span></h3><p>相对熵不为负：</p>
<script type="math/tex; mode=display">D(p||q)\geq0,\ D(q||p)\geq0</script><p>且相对熵公式只有在$p(x_i)$等于$q(x_i)$时等于0。</p>
<p><font face="仿宋"><br>证明：要证明</font></p>
<script type="math/tex; mode=display">D_{KL}(p||q)=\sum_{i=1}^n\left(p(x_i)\log{p(x_i)}-p(x_i)\log{q(x_i)}\right)\geq0</script><p><font face="仿宋"><br>即证</font></p>
<script type="math/tex; mode=display">\sum_{i=1}^np(x_i)\log{\frac{q(x_i)}{p(x_i)}}\leq0</script><p><font face="仿宋"><br>因为$\ln{x}\leq x-1$当且仅当$x=1$时等号成立，所以</font></p>
<script type="math/tex; mode=display">\sum_{i=1}^np(x_i)\log{\frac{q(x_i)}{p(x_i)}}\leq\sum_{i=1}^np(x_i)\left(\frac{q(x_i)}{p(x_i)}-1\right)=\sum_{i=1}^n\left(q(x_i)-p(x_i)\right)</script><p><font face="仿宋">当且仅当$p(x_i)=q(x_i)$（对所有的$i,\ i=1,2,\cdots,n$）时有</font></p>
<script type="math/tex; mode=display">\sum_{i=1}^np(x_i)\log{\frac{q(x_i)}{p(x_i)}}=\sum_{i=1}^n\left[q(x_i)-p(x_i)\right]=0</script><h1><span id="交叉熵">交叉熵</span></h1><p>交叉熵（Cross entropy）：是一种损失函数/代价函数，用于描述模型预测值与真实值的差距大小。</p>
<p>真实概率分布$p(x)$和预测概率分布$q(x)$之间的交叉熵为</p>
<script type="math/tex; mode=display">H(p,q)=-\sum_{i=1}^np(x_i)\log{q(x_i)}</script><p>交叉熵在分类问题中，常常与softmax搭配使用，softmax将输出的结果进行处理，使多个分类类别的预测值的和为1，再使用交叉熵计算损失。</p>
<p>将KL散度公式拆开：<br>\begin{equation}<br>\begin{aligned}<br>  D_{KL}(p||q)&amp;=\sum_{i=1}^np(x_i)\log{\frac{p(x_i)}{q(x_i)}}\\<br>&amp;= \underline{\sum_{i=1}^np(x_i)\log{p(x_i)}}-\sum_{i=1}^np(x_i)\log{q(x_i)}\\<br>&amp;= \underline{-H\left(p(x)\right)}+\left[-\sum_{i=1}^np(x_i)\log{q(x_i)} \right]<br>\end{aligned}<br>\end{equation}<br>其中，$H\left(p(x)\right)$表示真实分布的信息熵，后者即为交叉熵。</p>
<script type="math/tex; mode=display">KL散度=交叉熵-信息熵</script><p>KL散度（相对熵）衡量的是真实概率分布与预测概率分布之间的差异；KL散度越小，表明预测的效果越好。在机器学习训练模型时，输入数据（Input）与标签（Label）通常已确定，那么真实概率分布$p$也已确定，信息熵$H\left(p(x)\right)$就是一个常量。因此，最小化KL散度等价于最小化交叉熵。所以，在机器学习中常常使用交叉熵作为损失函数。</p>
<h1><span id="互信息">互信息</span></h1><p>互信息（Mutual Information）：也是信息论中的一种信息度量，是一个随机变量中包含的关于另一个随机变量的信息量，或者说，是一个随机变量由于已知另一个随机变量而减少的不确定性。</p>
<ul>
<li>两个<strong>离散</strong>随机变量$X$和$Y$的互信息定义为<script type="math/tex; mode=display">I(X,Y)=\sum_{y\in Y}\sum_{x\in X}p(x,y)\log{\frac{p(x,y)}{p(x)p(y)}}</script>其中，$p(x,y)$是$X$和$Y$的联合概率分布函数，$p(x)$、$p(y)$分别是$X$和$Y$的边缘概率分布函数。</li>
<li><p>两个<strong>连续</strong>随机变量的互信息定义为</p>
<script type="math/tex; mode=display">I(X,Y)=\int_Y\int_Xp(x,y)\log{\frac{p(x,y)}{p(x)p(y)}}\mathrm{d}x\mathrm{d}y</script><p>其中，$p(x,y)$是$X$和$Y$的联合概率密度函数，$p(x)$、$p(y)$分别是$X$和$Y$的边缘概率密度函数。</p>
</li>
<li><p>互信息是互信息量$I(x_i,y_j)$在联合概率空间中的统计平均值。</p>
</li>
<li>（平均）互信息克服了互信息量$I(x_i,y_j)$的随机性，是一个确定的量。</li>
<li>互信息是$X$和$Y$的联合分布相对于假定$X$和$Y$独立情况下的联合分布之间的内在依赖性。</li>
<li>$I(X,Y)=0$当且仅当$X$和$Y$独立时成立。</li>
<li>当$X$和$Y$独立时，$p(x,y)=p(x)p(y)$。因此<script type="math/tex; mode=display">\log{\frac{p(x,y)}{p(x)p(y)}}=\log1=0</script></li>
</ul>
<p><meta name="referrer" content="no-referrer"><br></p>
<h1><span id="参考资料">参考资料</span></h1><ul>
<li><a href="https://zhuanlan.zhihu.com/p/26486223" target="_blank" rel="noopener">通俗理解信息熵</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_6e85bf420100ohma.html" target="_blank" rel="noopener">ID3算法</a></li>
<li><a href="https://ask.julyedu.com/question/6897" target="_blank" rel="noopener">“熵”的通俗解释</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/26551798" target="_blank" rel="noopener">通俗理解条件熵</a></li>
<li><a href="https://blog.csdn.net/xierhacker/article/details/53463567" target="_blank" rel="noopener">机器学习笔记十：各种熵总结</a></li>
<li><a href="https://blog.csdn.net/weixinhum/article/details/85064685" target="_blank" rel="noopener">相对熵（KL散度）</a></li>
<li><a href="https://blog.csdn.net/BigData_Mining/article/details/81279612" target="_blank" rel="noopener">互信息的深度理解</a></li>
<li><a href="https://blog.csdn.net/NeilGY/article/details/98216164" target="_blank" rel="noopener">机器学习中各种熵</a></li>
<li><a href="https://www.cnblogs.com/kyrieng/p/8694705.html" target="_blank" rel="noopener">详解机器学习中的熵、条件熵、相对熵和交叉熵</a></li>
<li><a href="https://www.jiqizhixin.com/graph/technologies/1786086f-5b63-4eee-b9ed-dad4d64cdc86" target="_blank" rel="noopener">交叉熵</a></li>
<li><a href="https://blog.csdn.net/b1055077005/article/details/100152102" target="_blank" rel="noopener">交叉熵损失函数原理详解</a></li>
<li><a href="https://www.zhihu.com/question/65288314/answer/244557337" target="_blank" rel="noopener">为什么交叉熵可以用于计算代价</a></li>
</ul>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E7%AE%97%E6%B3%95/">算法</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E7%AE%97%E6%B3%95/">算法</a>
                    
                      <a class="hover-with-bg" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
                    
                      <a class="hover-with-bg" href="/tags/%E5%9F%BA%E7%A1%80/">基础</a>
                    
                  </div>
                
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <script defer src="https://utteranc.es/client.js"
          repo="ShootingWang/CommentsForBlog"
          issue-term="pathname"
  
          theme="github-light"
          crossorigin="anonymous"
  >
  </script>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    
  <div>
    
      <!-- 不蒜子统计PV -->
      
      <span id="busuanzi_container_site_pv" style="display: none">
      总访问量 <span id="busuanzi_value_site_pv"></span> 次
    </span>
    
    
      <!-- 不蒜子统计UV -->
      
      <span id="busuanzi_container_site_uv" style="display: none">
      总访客数 <span id="busuanzi_value_site_uv"></span> 人
    </span>
    
  </div>


    

    
  </div>
</footer>



<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 5,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>







  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "熵&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>








<!-- MathJax -->
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
            const display = !!node.type.match(/; *mode=display/);
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
            const text = document.createTextNode('');
            node.parentNode.replaceChild(text, node);
            math.start = { node: text, delim: '', n: 0 };
            math.end = { node: text, delim: '', n: 0 };
            doc.math.push(math);
          });
        }, '', false],
        insertedScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            let target = node.parentNode;
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax');
            }
          });
        }, '', false]
      }
    }
  };
</script>

<script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>















<script src="/js/prism/clipboard.js"></script>
<script src="/js/prism/prism.js" async></script>

{% if theme.mermaid.enable %}
  <script src='https://unpkg.com/mermaid@{{ theme.mermaid.version }}/dist/mermaid.min.js'></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({{ JSON.stringify(theme.mermaid.options) }});
    }
  </script>
{% endif %}<!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
