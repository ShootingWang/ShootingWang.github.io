<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon2.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="统计一只狗，梦想有只猫">
  <meta name="author" content="ShootingWang">
  <meta name="keywords" content="">
  <title>算法-LogisticRegression - ShootingWang</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_fmb4a04yx8h.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_ijqayz9ro8k.css">




<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<link rel="stylesheet" href="/js/prism/prism.css">

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>ShootingWang</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">
              <i class="iconfont icon-home-fill"></i>
              首页</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">
              <i class="iconfont icon-archive-fill"></i>
              归档</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">
              <i class="iconfont icon-category-fill"></i>
              分类</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">
              <i class="iconfont icon-tags-fill"></i>
              标签</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">
              <i class="iconfont icon-user-fill"></i>
              关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/bg/MalhamStars.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <div class="mt-3 post-meta">
                  <i class="iconfont icon-date-fill" aria-hidden="true"></i>
                  <time datetime="2020-05-15 17:24">
                    星期五, 五月 15日 2020, 5:24 下午
                  </time>
                </div>
              

              <div class="mt-1">
                
                  
                  <span class="post-meta mr-2">
                    <i class="iconfont icon-chart"></i>
                    2.1k 字
                  </span>
                

                
                  
                  <span class="post-meta mr-2">
                      <i class="iconfont icon-clock-fill"></i>
                    
                    
                    32
                     分钟
                  </span>
                

                
              </div>
            
          </div>

          
        </div>

        <a href="https://github.com/ShootingWang" class="attachment-full size-full" aria-label="Fork me on GitHub">
          <svg width="80" height="80" viewBox="0 0 250 250" style="fill:#fff; color:#151513; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true">
            <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
            <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
            <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path>
          </svg>
        </a>
        <style>

        .github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}
        </style>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <h1><span id="logistic-regression">Logistic Regression</span></h1><p>逻辑回归（<strong>LR</strong>，Logistic Regression），是一种<u>对数几率模型</u>（Logit Model），常用于二分类问题（binary classification problems）</p>
<ul>
<li>逻辑回归和线性回归（Linear Regression）都是一种广义线性模型（GLM，Generalized Linear Model）</li>
<li>属于<strong>有监督学习</strong>（Supervised Learning）</li>
<li>是一种分类器（Classifier）</li>
<li>因变量是分类变量（Qualitative response）</li>
</ul>
<blockquote>
<p>其他分类器有：</p>
<ul>
<li>判别分析（Discriminant Analysis）</li>
<li>决策树（Decision Tree）</li>
<li>随机森林（Random Forest）</li>
<li>支持向量机（Support Vector Machine）</li>
<li>神经网络（Neural Network）</li>
<li>……</li>
</ul>
</blockquote>
<h2><span id="逻辑分布">逻辑分布</span></h2><p>Logistic分布是一种连续型分布，其分布函数（Cumulative distribution function）为</p>
<script type="math/tex; mode=display">F(x)=P(X\leq x)=\frac{1}{1+e^{-(x-\mu)/s}}=\frac{1}{2}+\frac{1}{2}\tanh\left(\frac{x-\mu}{2s}\right)</script><p><meta name="referrer" content="no-referrer"><br><img src="/2020/05/15/%E7%AE%97%E6%B3%95-LogisticRegression/LR-CDF.png" srcset="/img/loading.gif" class title="不同取值参数对应的CDF"></p>
<p>概率密度函数为</p>
<script type="math/tex; mode=display">f(x)=F^\prime(x)=\frac{e^{-(x-\mu)/s}}{s\left(1+e^{-(x-\mu)/s}\right)^2}=\frac{1}{4s}\mathrm{sech}^2\left(\frac{x-2\mu}{2s}\right),\quad -\infty< x< +\infty</script><p>其中</p>
<ul>
<li>$\mu$为位置参数（location parameter）</li>
<li>$s$为尺度参数（scale parameter）</li>
<li>期望<script type="math/tex; mode=display">\mathrm{E(X)}=\mu</script></li>
<li>中位数<script type="math/tex; mode=display">\mathrm{Median(X)}=\mu</script></li>
<li>方差<script type="math/tex; mode=display">\mathrm{Var}(X)=\frac{s^2\pi^2}{3}</script></li>
</ul>
<p><meta name="referrer" content="no-referrer"><br><img src="/2020/05/15/%E7%AE%97%E6%B3%95-LogisticRegression/LR-pdf.png" srcset="/img/loading.gif" class title="不同取值参数对应的pdf"></p>
<h2><span id="逻辑函数">逻辑函数</span></h2><p>一个简单的Logistic函数：</p>
<script type="math/tex; mode=display">P(t)=\frac{1}{1+e^{-t}}</script><p><meta name="referrer" content="no-referrer"><br><img src="/2020/05/15/%E7%AE%97%E6%B3%95-LogisticRegression/LR-slog.png" srcset="/img/loading.gif" class title="标准Logistic函数"></p>
<p>广义Logistic曲线可以模拟一些人口增长的S形曲线：初始阶段大致是指数增长；然后开始变得饱和，增加变慢；最后，达到成熟时增加停止。</p>
<h2><span id="逻辑回归">逻辑回归</span></h2><p>逻辑回归通常用于二分类问题（因变量是分类变量），用来表示某件事发生的可能性。</p>
<p>Andrew Ng的CS229中的例子：根据肿瘤的大小（Tumor Size）$X$来判断肿瘤是否是恶性的（Malignant）$Y$。</p>
<p>考虑构建线性回归模型$h_\theta(x)$，$h_\theta(x)\geq 0.5$ 为恶性肿瘤，$h_\theta(x)&lt;0.5$为良性肿瘤。<br>\begin{equation}<br>  Y=\left\{<br>\begin{array}{ll}<br>1, &amp; \mbox{如果} h_\theta(x)\geq 0.5\\<br>0, &amp; \mbox{如果} h_\theta(x)&lt;0.5<br>\end{array}\right.<br>\end{equation}</p>
<p>Logistic函数/<strong>Sigmoid函数</strong>可以将任意实数值映射到(0,1)区间（不包括0和1，但可以无限接近）。因此，使用Sigmoid函数来将线性回归的结果按照一定的阈值分为2类（二分类问题）或更多类（多分类问题）。</p>
<p><meta name="referrer" content="no-referrer"><br><img src="/2020/05/15/%E7%AE%97%E6%B3%95-LogisticRegression/LR-heart.png" srcset="/img/loading.gif" class title="来自：机器之心-从原理到应用-简述Logistic回归算法"></p>
<p>令</p>
<script type="math/tex; mode=display">h_\theta(x)=g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}=\frac{e^{\theta^Tx}}{1+e^{\theta^Tx}}</script><p>其中$z=\theta^Tx$（这里$x$包含截距项），Sigmoid函数为</p>
<script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}=\frac{e^z}{1+e^z}</script><p>Sigmoid保证$h_\theta(x)$取值在0和1之间（概率取值范围为[0,1]）。</p>
<p><strong>Log-odds</strong>，也称<strong>Logit</strong>（Logit transformation / Link function）表示为</p>
<script type="math/tex; mode=display">\log\frac{p}{1-p}=\log\frac{h_\theta(x)}{1-h_\theta(x)}=\theta^Tx</script><p>其中$p=h_\theta(x)$表示概率。</p>
<p>$h_\theta(x)$表示输入$x$后分类结果为1的概率</p>
<script type="math/tex; mode=display">P(Y=1|x;\theta)=h_\theta(x)</script><script type="math/tex; mode=display">P(Y=0|x;\theta)=1-h_\theta(x)</script><p>\newpage<br>\noindent 因此，因变量$Y$服从Bernoulli分布</p>
<script type="math/tex; mode=display">Y|X=x_i\sim \mathrm{Bernoulli}\left(h_\theta(x_i)\right)</script><p>概率函数为</p>
<script type="math/tex; mode=display">P(y|x;\theta)=\left[h_\theta(x) \right]^y\left[1-h_\theta(x) \right]^{1-y}</script><p>使用训练数据集$x=\{x_1,x_2,\cdots,x_n\}$（特征数据）和$y=\{y_1,y_2\cdots,y_n\}$（分类数据）构建回归模型。</p>
<p>如何求解逻辑回归方程中的参数？通常使用极大似然法。</p>
<h2><span id="极大似然法">极大似然法</span></h2><p>$n$个独立样本的似然函数为</p>
<script type="math/tex; mode=display">L(\theta)=\Pi_{i=1}^nP(y_i|x_i;\theta)=\Pi_{i=1}^nh_\theta(x_i)^{y_i}\left[1-h_\theta(x_i) \right]^{1-y_i}</script><p>对数似然函数为<br>\begin{equation}<br>\begin{aligned}<br>  l(\theta)=\log{L(\theta)}&amp;=\sum_{i=1}^n\left\{y_i\log{h_\theta(x_i)}+(1-y_i)\log{\left[1-h_\theta(x_i) \right]}\right\}\\<br>  &amp;= \sum_{i=1}^n\left\{y_i\theta^Tx_i-\log{\left[1+e^{\theta^Tx_i} \right]}\right\}<br>\end{aligned}<br>\end{equation}<br>其中</p>
<script type="math/tex; mode=display">\log{h_\theta(x_i)}=\log{\frac{e^{\theta^Tx_i}}{1+e^{\theta^Tx_i}}}=\theta^Tx_i-\log{\left[1+e^{\theta^Tx_i}\right]}</script><script type="math/tex; mode=display">\log{\left[1-h_\theta(x_i)\right]}=\log{\frac{1}{1+e^{\theta^Tx_i}}}=-\log{\left[1+e^{\theta^Tx_i}\right]}</script><script type="math/tex; mode=display">\max{L(\theta)}\Leftrightarrow\max{l(\theta)}\Leftrightarrow\min{\{-l(\theta)\}}</script><p>其中$-l(\theta)=-\log{L(\theta)}$称为<strong>交叉熵误差函数</strong>（cross-entropy error function）。</p>
<p>考虑$p+1$维的参数$\theta=(\theta_0,\theta_1,\cdots,\theta_p)^T$，其中$\theta_0$ 为线性回归方程$z=\theta^Tx$的截距。<br>\begin{equation}<br>\theta=\left(<br>\begin{array}{c}<br>  \theta_0\\<br>  \theta_1\\<br>  \theta_2\\<br>  \vdots\\<br>  \theta_p<br>\end{array}<br>\right),\quad<br>x_i=\left(<br>\begin{array}{c}<br>  1\\<br>  x_{i1}\\<br>  x_{i2}\\<br>  \vdots\\<br>  x_{ip}<br>\end{array}<br>\right)<br>\end{equation}<br>对数似然函数$l(\theta)$分别对$\theta_j\ (j=0,1,\cdots,p)$求偏导，并令导数为零</p>
<script type="math/tex; mode=display">\frac{\partial{l(\theta)}}{\partial{\theta_j}}=\sum_{i=1}^n\left\{y_ix_{ij}-\frac{e^{\theta^Tx_i}}{1+e^{\theta^Tx_i}}x_{ij}\right\}=\sum_{i=1}^n\left\{x_{ij}\left[y_i-h_\theta(x_i) \right]\right\}=0</script><p>写成向量形式</p>
<script type="math/tex; mode=display">\frac{\partial{l(\theta)}}{\partial{\theta}}=\sum_{i=1}^n\left\{x_i\left[y_i-h_\theta(x_i) \right]\right\}=0</script><p>该式也被称为<strong>score equation</strong>。</p>
<p>这里$x_i$的一个元素为1，因此由上式可得</p>
<script type="math/tex; mode=display">\sum_{i=1}^ny_i=\sum_{i=1}^nh_\theta(x_i)</script><p>表示$Y$取值为1的样本量（$n$个样本中得恶性肿瘤的人数）等于“事件”（如肿瘤为恶性肿瘤）发生的概率和。</p>
<p>当$p$较小时，score equation可得到解析解（精确解）；但当$p$较大时，score equation 往往得不到解析解。这时，可以考虑使用Newton-Raphson算法求得数值解（numerical solution）。</p>
<h2><span id="newton-raphson算法">Newton-Raphson算法</span></h2><p>首先计算二阶偏导（Hessian Matrix）：<br>\begin{equation}<br>\begin{aligned}<br>\frac{\partial^2l(\theta)}{\partial{\theta_k}\partial{\theta_j}}&amp;=\frac{\partial}{\partial{\theta_k}}\sum_{i=1}^n\left\{x_{ij}\left[y_i-h_\theta(x_i)\right]\right\}\\<br>&amp;=\frac{\partial}{\partial{\theta_k}}\sum_{i=1}^n\left\{x_{ij}\left[y_i-\frac{e^{\theta^Tx_i}}{1+e^{\theta^Tx_i}}\right]\right\}\\<br>&amp;=\sum_{i=1}^nx_{ij}\left\{-\frac{e^{\theta^Tx_i}x_{ik}(1+e^{\theta^Tx_i})-e^{\theta^Tx_i}e^{\theta^Tx_i}x_{ik}}{\left(1+e^{\theta^Tx_i}\right)^2}\right\}\\<br>&amp;=-\sum_{i=1}^nx_{ij}x_{ik}\frac{e^{\theta^Tx_i}}{1+e^{\theta^Tx_i}}\left(1-\frac{e^{\theta^Tx_i}}{1+e^{\theta^Tx_i}}\right)\\<br>&amp;=-\sum_{i=1}^nx_{ij}x_{ij}h_\theta(x_i)\left[1-h_\theta(x_i)\right]<br>\end{aligned}<br>\end{equation}<br>其中$j,k=0,1,\cdots,p$。</p>
<p><strong>Hessian Matrix</strong>为</p>
<script type="math/tex; mode=display">\frac{\partial^2l(\theta)}{\partial\theta\partial\theta^T}=-\sum_{i=1}^nx_ix_i^Th_\theta(x_i)[1- h_\theta(x_i)]</script><p>由$\theta^{old}$开始，Newton-Raphson的更新步骤（updating step）为</p>
<script type="math/tex; mode=display">\theta^{new}=\theta^{old}-\left[\frac{\partial^2l(\theta)}{\partial\theta\partial\theta^T}\right]^{-1}\frac{\partial{l(\theta)}}{\partial\theta}</script><p>这里考虑步长为1的pure Newton’s Method。即</p>
<script type="math/tex; mode=display">\theta^{new}=\theta^{old}-\alpha\left[\frac{\partial^2l(\theta)}{\partial\theta\partial\theta^T}\right]^{-1}\frac{\partial{l(\theta)}}{\partial\theta}\quad \mbox{with}\ \alpha=1</script><p>用矩阵形式表示<br>\begin{equation}<br>\mathbf{y}=\left(<br>\begin{array}{c}<br>  y_1\\<br>  y_2\\<br>  \vdots\\<br>  y_n<br>\end{array}<br>\right),\quad<br>\mathbf{X}=\left(<br>\begin{array}{c}<br>  x_1^T\\<br>  x_2^T\\<br>  \vdots\\<br>  x_n^T<br>\end{array}<br>\right)=<br>\left(<br>\begin{array}{ccccc}<br>  1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\<br>  1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\<br>  \vdots &amp; \vdots &amp; \vdots &amp;\ddots &amp; \vdots \\<br>  1 &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}<br>\end{array}<br>\right)<br>\end{equation}</p>
<p>\begin{equation}<br>\mathbf{P}=\left(<br>\begin{array}{c}<br>  h_{\theta^{old}}(x_1)\\<br>  h_{\theta^{old}}(x_2)\\<br>  \vdots\\<br>  h_{\theta^{old}}(x_n)<br>\end{array}<br>\right),\quad<br>\mathbf{W}=\mathrm{diag}\left\{<br>  h_{\theta^{old}}(x_i)(1-h_{\theta^{old}}(x_i))<br>\right\}<br>\end{equation}</p>
<p>则有</p>
<script type="math/tex; mode=display">\frac{\partial{l(\theta)}}{\partial\theta}=\mathbf{X}^T(\bm{y}-\bm{P})</script><script type="math/tex; mode=display">\frac{\partial^2l(\theta)}{\partial\theta\partial\theta^T}=-\mathbf{X}^T\mathbf{W}\mathbf{X}</script><p>因此<br>\begin{equation}<br>\begin{aligned}<br>\theta^{new}&amp;=\theta^{old}-\left[\frac{\partial^2l(\theta)}{\partial\theta\partial\theta^T} \right]^{-1}\frac{\partial{l(\theta)}}{\partial\theta}\\<br>&amp;= \theta^{old}+\left(\mathbf{X}^T\mathbf{W}\mathbf{X}\right)^{-1}\mathbf{X}^T(\bf{y}-\bf{P})\\<br>&amp;= \left(\mathbf{X}^T\mathbf{W}\mathbf{X}\right)^{-1}\mathbf{X}^T\mathbf{W}\left[\mathbf{X}\theta^{old}+\mathbf{W}^{-1}(\mathbf{y}-\mathbf{P}) \right]\\<br>&amp;= \left(\mathbf{X}^T\mathbf{W}\mathbf{X}\right)^{-1}\mathbf{X}^T\mathbf{W}\mathbf{z}<br>\end{aligned}<br>\end{equation}</p>
<p>其中$\mathbf{z}=\mathbf{X}\theta^{old}+\mathbf{W}^{-1}(\mathbf{y}-\mathbf{P})$。</p>
<p>每次迭代中，$\bf{P}$更新，$\bf{W}$和$\bf{z}$也随之更新。</p>
<p>$\theta^{new}$可以看作是$\bf{z}$关于$\bf{X}$回归的加权最小二乘（weighted least square）。</p>
<p>式</p>
<script type="math/tex; mode=display">\theta^{new}=\left(\mathbf{X}^T\mathbf{W}\mathbf{X}\right)^{-1}\mathbf{X}^T\mathbf{W}\mathbf{z}</script><p>这种迭代法也称为迭代重加权最小二乘（iteratively reweighted least squares，IRLS）。</p>
<h1><span id="逻辑回归-vs-线性回归">逻辑回归 vs 线性回归</span></h1><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center"><strong>逻辑回归</strong></th>
<th style="text-align:center"><strong>线性回归</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">分类</td>
<td style="text-align:center">回归</td>
</tr>
<tr>
<td style="text-align:center"><strong>因变量</strong></td>
<td style="text-align:center">离散的变量</td>
<td style="text-align:center">连续的变量</td>
</tr>
<tr>
<td style="text-align:center"><strong>自变量与因变量</strong></td>
<td style="text-align:center">可以不符合线性关系</td>
<td style="text-align:center">符合线性关系</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">无法直观表达变量关系</td>
<td style="text-align:center">直观表达变量关系</td>
</tr>
</tbody>
</table>
</div>
<h1><span id="参考资料">参考资料</span></h1><ul>
<li><a href="https://zh.wikipedia.org/wiki/%E9%82%8F%E8%BC%AF%E8%BF%B4%E6%AD%B8" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E9%82%8F%E8%BC%AF%E8%BF%B4%E6%AD%B8</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/28408516" target="_blank" rel="noopener">逻辑回归（Logistic Regression）（一）</a></li>
<li><a href="https://en.wikipedia.org/wiki/Logistic_distribution" target="_blank" rel="noopener">维基百科-逻辑分布</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E9%82%8F%E8%BC%AF%E5%87%BD%E6%95%B8" target="_blank" rel="noopener">维基百科-逻辑函数</a></li>
<li><a href="https://www.jiqizhixin.com/articles/2018-05-13-3" target="_blank" rel="noopener">从原理到应用-简述Logistic回归算法</a></li>
<li><a href="https://www.cnblogs.com/sparkwen/p/3441197.html" target="_blank" rel="noopener">逻辑回归模型基础</a></li>
<li><a href="https://easyai.tech/ai-definition/logistic-regression/" target="_blank" rel="noopener">逻辑回归</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/67842740" target="_blank" rel="noopener">Logistic回归，梯度下降法，牛顿法，IRLS算法</a></li>
<li><a href="https://blog.csdn.net/u012526120/article/details/48897135" target="_blank" rel="noopener">Logistic和牛顿法</a></li>
<li><a href="https://www.afenxi.com/56409.html" target="_blank" rel="noopener">如何在R中执行Logistic回归？</a></li>
<li><a href="https://www.cnblogs.com/nxld/p/6170690.html" target="_blank" rel="noopener">如何在R语言中使用Logistic回归模型</a></li>
<li><a href="https://blog.csdn.net/zllnau66/article/details/81742798" target="_blank" rel="noopener">Python3常用的数据清洗方法</a></li>
<li><a href="https://www.cnblogs.com/wuchuanying/p/6243987.html" target="_blank" rel="noopener">Python_Sklearn机器学习库学习笔记（三）</a></li>
</ul>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E7%AE%97%E6%B3%95/">算法</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E7%AE%97%E6%B3%95/">算法</a>
                    
                      <a class="hover-with-bg" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
                    
                  </div>
                
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <script defer src="https://utteranc.es/client.js"
          repo="ShootingWang/CommentsForBlog"
          issue-term="pathname"
  
          theme="github-light"
          crossorigin="anonymous"
  >
  </script>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    
  <div>
    
      <!-- 不蒜子统计PV -->
      
      <span id="busuanzi_container_site_pv" style="display: none">
      总访问量 <span id="busuanzi_value_site_pv"></span> 次
    </span>
    
    
      <!-- 不蒜子统计UV -->
      
      <span id="busuanzi_container_site_uv" style="display: none">
      总访客数 <span id="busuanzi_value_site_uv"></span> 人
    </span>
    
  </div>


    

    
  </div>
</footer>



<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 5,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>







  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "算法-LogisticRegression&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>








<!-- MathJax -->
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
            const display = !!node.type.match(/; *mode=display/);
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
            const text = document.createTextNode('');
            node.parentNode.replaceChild(text, node);
            math.start = { node: text, delim: '', n: 0 };
            math.end = { node: text, delim: '', n: 0 };
            doc.math.push(math);
          });
        }, '', false],
        insertedScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            let target = node.parentNode;
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax');
            }
          });
        }, '', false]
      }
    }
  };
</script>

<script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>















<script src="/js/prism/clipboard.js"></script>
<script src="/js/prism/prism.js" async></script>

{% if theme.mermaid.enable %}
  <script src='https://unpkg.com/mermaid@{{ theme.mermaid.version }}/dist/mermaid.min.js'></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({{ JSON.stringify(theme.mermaid.options) }});
    }
  </script>
{% endif %}

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
